import { VoiceState } from '@/types/voice';

export interface StepFunConfig {
  apiKey: string;
  model?: string;
  voice?: string;
  instructions?: string;
}

export class StepFunRealtimeClient {
  private ws: WebSocket | null = null;
  private config: StepFunConfig;
  private onStateChange?: (state: VoiceState) => void;
  private onTranscript?: (text: string) => void;
  private onAudio?: (audioData: ArrayBuffer) => void;
  private audioContext: AudioContext | null = null;
  private audioQueue: AudioBuffer[] = [];
  private isPlaying: boolean = false;
  private sourceNode: AudioBufferSourceNode | null = null;

  constructor(config: StepFunConfig) {
    this.config = {
      model: 'step-audio-2-mini',  // ä½¿ç”¨ step-audio-2-mini æ¨¡å‹
      voice: 'qingchunshaonv',  // step-audio-2-mini åªæ”¯æŒé’æ˜¥å°‘å¥³å’Œæ¸©æŸ”ç”·å£°
      instructions: 'ä½ æ˜¯ç”±é˜¶è·ƒæ˜Ÿè¾°æä¾›çš„AIèŠå¤©åŠ©æ‰‹ï¼Œä½ æ“…é•¿ä¸­æ–‡ï¼Œè‹±æ–‡ï¼Œä»¥åŠå¤šç§å…¶ä»–è¯­è¨€çš„å¯¹è¯ã€‚è¯·ç®€æ´å‹å¥½åœ°å›ç­”ï¼Œæ¯æ¬¡å›ç­”ä¸è¶…è¿‡50å­—ã€‚è¯·ä½¿ç”¨é»˜è®¤å¥³å£°ä¸ç”¨æˆ·äº¤æµã€‚',
      ...config,
    };

    // éªŒè¯éŸ³è‰²æ˜¯å¦æœ‰æ•ˆ
    const validVoices = ['qingchunshaonv', 'wenrounansheng'];
    if (!validVoices.includes(this.config.voice || '')) {
      console.warn(`âš ï¸ Invalid voice for step-audio-2-mini: ${this.config.voice}`);
      console.warn(`ğŸ”„ Auto-changing to: qingchunshaonv`);
      this.config.voice = 'qingchunshaonv';
    }
  }

  async connect(
    onStateChange: (state: VoiceState) => void,
    onTranscript: (text: string) => void,
    onAudio: (audioData: ArrayBuffer) => void
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      this.onStateChange = onStateChange;
      this.onTranscript = onTranscript;
      this.onAudio = onAudio;

      try {
        // è¿æ¥åˆ°æœ¬åœ°ä»£ç†æœåŠ¡å™¨
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const host = window.location.host;
        const wsUrl = `${protocol}//${host}/api/ws-proxy?apiKey=${encodeURIComponent(this.config.apiKey)}`;

        console.log('Connecting to proxy:', wsUrl.replace(/apiKey=[^&]+/, 'apiKey=***'));
        console.log('Model (via URL): step-audio-2-mini');
        console.log('Using voice:', this.config.voice);

        this.ws = new WebSocket(wsUrl);
        this.audioContext = new AudioContext({ sampleRate: 24000 });

        this.ws.onopen = () => {
          console.log('âœ… WebSocket connected to proxy');
          onStateChange('idle');

          // è¿æ¥æˆåŠŸååˆ›å»ºä¼šè¯
          this.sendSessionUpdate();
          resolve();
        };

        this.ws.onmessage = async (event) => {
          try {
            const data = JSON.parse(event.data);
            await this.handleEvent(data);
          } catch (error) {
            console.error('Failed to parse message:', error);
          }
        };

        this.ws.onerror = (error) => {
          console.error('âŒ WebSocket error:', error);
          onStateChange('idle');
          alert('è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®');
          reject(error);
        };

        this.ws.onclose = (event) => {
          console.log('ğŸ”Œ WebSocket closed:', event.code, event.reason);
          if (event.code !== 1000) {
            console.error('âŒ Connection closed abnormally. Code:', event.code);
          }
          onStateChange('idle');
        };
      } catch (error) {
        console.error('Failed to connect:', error);
        onStateChange('idle');
        reject(error);
      }
    });
  }

  private sendSessionUpdate() {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    const sessionUpdate = {
      event_id: this.generateEventId(),
      type: 'session.update',
      session: {
        modalities: ['text', 'audio'],
        instructions: this.config.instructions,
        voice: this.config.voice,
        input_audio_format: 'pcm16',
        output_audio_format: 'pcm16',
        turn_detection: {
          type: 'server_vad',
        },
      },
    };

    console.log('ğŸ“¤ Sending session update');
    console.log('   Voice:', this.config.voice);
    this.ws.send(JSON.stringify(sessionUpdate));
    console.log('âœ… Session update sent');
  }

  private async handleEvent(event: any) {
    console.log('ğŸ“¥ Received event:', event.type);

    switch (event.type) {
      case 'session.created':
      case 'session.updated':
        console.log('âœ… Session event:', event);
        break;

      case 'input_audio_buffer.speech_started':
        console.log('ğŸ¤ Speech started');
        this.onStateChange?.('listening');
        break;

      case 'input_audio_buffer.speech_stopped':
        console.log('ğŸ¤” Speech stopped, thinking...');
        this.onStateChange?.('thinking');
        break;

      case 'response.audio.delta':
        // æ”¶åˆ°éŸ³é¢‘æ•°æ®
        if (event.delta) {
          const audioData = this.base64ToArrayBuffer(event.delta);
          this.onAudio?.(audioData);
        }
        break;

      case 'response.audio_transcript.delta':
        // æ”¶åˆ°æ–‡å­—è½¬å½•
        if (event.delta) {
          this.onTranscript?.(event.delta);
        }
        break;

      case 'response.audio.done':
      case 'response.audio_transcript.done':
        console.log('âœ… Response done');
        break;

      case 'error':
        console.error('âŒ Server error:', event.error);
        this.onStateChange?.('idle');
        const errorMsg = event.error?.message || event.error?.type || 'æœªçŸ¥é”™è¯¯';
        alert(`API é”™è¯¯: ${errorMsg}`);
        break;

      default:
        console.log('ğŸ“„ Unhandled event type:', event.type);
    }
  }

  sendAudio(audioData: Float32Array) {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    // å°† Float32Array è½¬æ¢ä¸º PCM16
    const pcm16Data = this.floatToPCM16(audioData);
    const base64Audio = this.arrayBufferToBase64(pcm16Data);

    const message = {
      event_id: this.generateEventId(),
      type: 'input_audio_buffer.append',
      audio: base64Audio,
    };

    this.ws.send(JSON.stringify(message));
  }

  startConversation() {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    const message = {
      event_id: this.generateEventId(),
      type: 'response.create',
    };

    this.ws.send(JSON.stringify(message));
    console.log('ğŸš€ Conversation started');
  }

  clearAudioBuffer() {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.error('WebSocket not connected');
      return;
    }

    const message = {
      event_id: this.generateEventId(),
      type: 'input_audio_buffer.clear',
    };

    this.ws.send(JSON.stringify(message));
  }

  disconnect() {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
  }

  isConnected(): boolean {
    return this.ws?.readyState === WebSocket.OPEN;
  }

  // å·¥å…·æ–¹æ³•ï¼šFloat32 è½¬ PCM16
  private floatToPCM16(float32Array: Float32Array): ArrayBuffer {
    const arrayBuffer = new ArrayBuffer(float32Array.length * 2);
    const view = new DataView(arrayBuffer);

    for (let i = 0; i < float32Array.length; i++) {
      const sample = Math.max(-1, Math.min(1, float32Array[i]));
      view.setInt16(i * 2, sample < 0 ? sample * 0x8000 : sample * 0x7fff, true);
    }

    return arrayBuffer;
  }

  // å·¥å…·æ–¹æ³•ï¼šArrayBuffer è½¬ Base64
  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return window.btoa(binary);
  }

  // å·¥å…·æ–¹æ³•ï¼šBase64 è½¬ ArrayBuffer
  private base64ToArrayBuffer(base64: string): ArrayBuffer {
    const binaryString = window.atob(base64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  }

  // å·¥å…·æ–¹æ³•ï¼šç”Ÿæˆäº‹ä»¶ ID
  private generateEventId(): string {
    return `event_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  // æ’­æ”¾éŸ³é¢‘æ•°æ®
  async playAudio(audioData: ArrayBuffer): Promise<void> {
    if (!this.audioContext) {
      console.error('AudioContext not initialized');
      return;
    }

    try {
      // å°† ArrayBuffer è½¬æ¢ä¸º AudioBuffer
      const pcm16Data = new DataView(audioData);
      const numberOfChannels = 1;
      const sampleRate = 24000;
      const frameCount = pcm16Data.byteLength / 2;

      const audioBuffer = this.audioContext.createBuffer(
        numberOfChannels,
        frameCount,
        sampleRate
      );

      const channelData = audioBuffer.getChannelData(0);
      for (let i = 0; i < frameCount; i++) {
        const sample = pcm16Data.getInt16(i * 2, true);
        channelData[i] = sample / 0x8000;
      }

      // æ·»åŠ åˆ°æ’­æ”¾é˜Ÿåˆ—
      this.audioQueue.push(audioBuffer);

      // å¦‚æœæ²¡æœ‰åœ¨æ’­æ”¾ï¼Œå¼€å§‹æ’­æ”¾
      if (!this.isPlaying) {
        this.playNextAudio();
      }
    } catch (error) {
      console.error('Failed to play audio:', error);
    }
  }

  private async playNextAudio() {
    if (this.audioQueue.length === 0) {
      this.isPlaying = false;
      this.onStateChange?.('idle');
      return;
    }

    this.isPlaying = true;
    this.onStateChange?.('speaking');

    const audioBuffer = this.audioQueue.shift()!;
    this.sourceNode = this.audioContext!.createBufferSource();
    this.sourceNode.buffer = audioBuffer;
    this.sourceNode.connect(this.audioContext!.destination);

    this.sourceNode.onended = () => {
      this.playNextAudio();
    };

    this.sourceNode.start();
  }

  stopPlayback() {
    if (this.sourceNode) {
      this.sourceNode.stop();
      this.sourceNode = null;
    }
    this.audioQueue = [];
    this.isPlaying = false;
  }
}
